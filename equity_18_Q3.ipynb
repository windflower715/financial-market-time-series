{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "#Pure technical time series analysis on stocks\n",
    "from collections import defaultdict\n",
    "from bbg.sapi import BbgSapi\n",
    "import pickle as pkl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "company = pd.read_excel('company.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "total = defaultdict()\n",
    "sapi = BbgSapi()\n",
    "stock_names= ['atus', 'amzn','armk','anet','azo']\n",
    "stock_tickers= ['ATUS US Equity', 'AMZN US Equity', 'ARMK US Equity','ANET US Equity','AZO US Equity']\n",
    "atus = sapi.bdh('ATUS US Equity', start_date ='1970-01-01')\n",
    "atus.set_index ('asofdate', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, j in zip(stock_names, stock_tickers): \n",
    "    total[i] = sapi.bdh(j,start_date = '1970-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('total.pkl','wb') as picklefile :\n",
    "    pkl.dump(total,picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pure LSTM time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load dataframe into properly shaped numpy arrays\n",
    "\"\"\"LSTM work by taking in a numpy array of 3 dimensions (N,M,F), \n",
    "N is the number of training sequence,\n",
    "W is the sequence length (the size of the window),\n",
    "F is the number of features of each sequence\n",
    "\"\"\"\n",
    "\n",
    "def load_data(df, seq_len, normalise_window):\n",
    "    result = np.array(df)\n",
    "    row = round(0.9* result.shape[0])\n",
    "    train = result[:int(row), :]\n",
    "    np.random.shuffle(train)\n",
    "    x_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    x_test = result[int(row):, :-1]\n",
    "    y_test = result[int(row):, -1]\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))  \n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([], shape=(272, 0, 1), dtype=float64),\n",
       " array([22.59, 33.44, 17.79, 27.3 , 22.76, 16.95, 19.03, 32.01, 18.42,\n",
       "        30.96, 18.41, 19.97, 30.01, 20.1 , 21.24, 32.35, 27.3 , 18.87,\n",
       "        32.27, 18.19, 31.05, 18.36, 19.21, 20.19, 20.9 , 22.75, 21.23,\n",
       "        29.5 , 25.15, 21.8 , 18.6 , 16.89, 21.3 , 17.92, 34.3 , 25.52,\n",
       "        20.23, 32.68, 30.69, 21.44, 31.02, 28.66, 21.67, 17.1 , 33.88,\n",
       "        16.57, 31.91, 20.97, 31.2 , 31.49, 19.25, 17.66, 20.48, 18.56,\n",
       "        32.91, 21.9 , 23.06, 17.51, 16.79, 18.71, 17.06, 18.71, 19.15,\n",
       "        17.32, 16.89, 27.93, 18.78, 21.47, 20.21, 19.81, 19.7 , 27.02,\n",
       "        31.9 , 18.41, 28.24, 30.89, 17.7 , 25.6 , 19.86, 31.34, 27.67,\n",
       "        21.9 , 19.56, 17.9 , 19.55, 22.83, 24.94, 17.9 , 31.09, 21.86,\n",
       "        29.69, 30.68, 27.  , 23.27, 20.08, 17.6 , 23.52, 30.  , 18.13,\n",
       "        32.86, 18.79, 19.33, 22.38, 18.67, 19.63, 20.25, 24.58, 20.34,\n",
       "        29.25, 27.53, 18.5 , 19.19, 31.04, 32.71, 21.01, 20.57, 18.33,\n",
       "        32.48, 26.75, 16.98, 25.4 , 19.33, 18.84, 31.  , 20.26, 16.43,\n",
       "        19.74, 21.09, 27.25, 23.13, 17.14, 18.2 , 24.5 , 30.55, 33.81,\n",
       "        17.64, 23.91, 32.57, 21.85, 18.48, 30.5 , 19.82, 19.9 , 19.54,\n",
       "        18.53, 30.85, 22.42, 18.36, 25.86, 19.35, 18.5 , 19.28, 24.49,\n",
       "        19.47, 32.3 , 21.35, 19.29, 31.88, 18.7 , 30.72, 17.74, 31.75,\n",
       "        23.88, 20.26, 19.26, 26.02, 21.53, 19.93, 20.5 , 20.42, 16.83,\n",
       "        19.08, 19.32, 30.86, 18.48, 17.14, 21.  , 31.05, 22.51, 31.9 ,\n",
       "        19.5 , 19.21, 26.94, 31.6 , 19.77, 30.29, 19.94, 17.64, 30.34,\n",
       "        26.99, 20.41, 18.11, 20.25, 19.76, 30.51, 19.86, 19.7 , 19.2 ,\n",
       "        23.69, 23.68, 18.44, 21.55, 20.05, 18.96, 24.65, 20.68, 21.1 ,\n",
       "        20.91, 18.  , 22.44, 23.11, 17.85, 16.95, 18.29, 18.97, 20.1 ,\n",
       "        17.59, 20.24, 19.03, 19.86, 27.22, 17.98, 18.52, 31.08, 16.8 ,\n",
       "        20.67, 19.01, 19.91, 17.89, 19.4 , 19.26, 27.35, 31.79, 31.44,\n",
       "        17.49, 27.31, 19.46, 29.48, 18.48, 30.41, 19.96, 18.86, 32.62,\n",
       "        19.4 , 19.35, 17.86, 20.69, 17.06, 18.59, 18.23, 18.63, 18.79,\n",
       "        31.08, 24.6 , 31.55, 32.45, 27.69, 28.19, 19.16, 20.59, 16.78,\n",
       "        19.94, 19.05, 25.11, 21.81, 31.1 , 31.64, 18.9 , 27.85, 26.72,\n",
       "        33.9 , 22.8 ]),\n",
       " array([], shape=(30, 0, 1), dtype=float64),\n",
       " array([17.27, 16.99, 16.76, 16.5 , 16.7 , 16.68, 16.35, 17.13, 17.03,\n",
       "        16.56, 17.25, 17.73, 17.37, 17.03, 17.58, 17.33, 17.29, 17.74,\n",
       "        17.35, 17.67, 17.5 , 18.12, 18.65, 18.15, 17.99, 18.05, 18.04,\n",
       "        18.04, 18.09, 17.85])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data(atus[['data_value']],50,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(\n",
    "        input_dim=layers[0],\n",
    "        output_dim=layers[1],\n",
    "        return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "        layers[2],\n",
    "        return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(\n",
    "        output_dim=layers[3]))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "    print(\"> Compilation Time : \", time.time() - start)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading data... \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fcf7a7324c5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'> Loading data... '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'> Data Loaded. Compiling...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-afb0bbc6ab2f>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(filename, seq_len, normalise_window)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalise_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0msequence_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not DataFrame"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "\n",
    "epochs  = 1\n",
    "seq_len = 50\n",
    "\n",
    "print('> Loading data... ')\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_data(atus[['data_value']], seq_len, True)\n",
    "\n",
    "print('> Data Loaded. Compiling...')\n",
    "\n",
    "model = lstm.build_model([1, 50, 100, 1])\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=512,\n",
    "    nb_epoch=epochs,\n",
    "    validation_split=0.05)\n",
    "\n",
    "predicted = predict_point_by_point(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename, seq_len, normalise_window):\n",
    "    f = open(filename, 'rb').read()\n",
    "    data = f.decode().split('\\n')\n",
    "\n",
    "    sequence_length = seq_len + 1\n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "    \n",
    "    if normalise_window:\n",
    "        result = normalise_windows(result)\n",
    "\n",
    "    result = np.array(result)\n",
    "\n",
    "    row = round(0.9 * result.shape[0])\n",
    "    train = result[:int(row), :]\n",
    "    np.random.shuffle(train)\n",
    "    x_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    x_test = result[int(row):, :-1]\n",
    "    y_test = result[int(row):, -1]\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))  \n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]\n",
    "\n",
    "def normalise_windows(window_data):\n",
    "    normalised_data = []\n",
    "    for window in window_data:\n",
    "        normalised_window = [((float(p) / float(window[0])) - 1) for p in window]\n",
    "        normalised_data.append(normalised_window)\n",
    "    return normalised_data\n",
    "\n",
    "def build_model(layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(\n",
    "        input_shape=(layers[1], layers[0]),\n",
    "        output_dim=layers[1],\n",
    "        return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "        layers[2],\n",
    "        return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(\n",
    "        output_dim=layers[3]))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "    print(\"> Compilation Time : \", time.time() - start)\n",
    "    return model\n",
    "\n",
    "def predict_point_by_point(model, data):\n",
    "    #Predict each timestep given the last sequence of true data, in effect only predicting 1 step ahead each time\n",
    "    predicted = model.predict(data)\n",
    "    predicted = np.reshape(predicted, (predicted.size,))\n",
    "    return predicted\n",
    "\n",
    "def predict_sequence_full(model, data, window_size):\n",
    "    #Shift the window by 1 new prediction each time, re-run predictions on new window\n",
    "    curr_frame = data[0]\n",
    "    predicted = []\n",
    "    for i in range(len(data)):\n",
    "        predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "        curr_frame = curr_frame[1:]\n",
    "        curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)\n",
    "    return predicted\n",
    "\n",
    "def predict_sequences_multiple(model, data, window_size, prediction_len):\n",
    "    #Predict sequence of 50 steps before shifting prediction run forward by 50 steps\n",
    "    prediction_seqs = []\n",
    "    for i in range(int(len(data)/prediction_len)):\n",
    "        curr_frame = data[i*prediction_len]\n",
    "        predicted = []\n",
    "        for j in range(prediction_len):\n",
    "            predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "            curr_frame = curr_frame[1:]\n",
    "            curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)\n",
    "        prediction_seqs.append(predicted)\n",
    "    return prediction_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [localpy]",
   "language": "python",
   "name": "Python [localpy]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
